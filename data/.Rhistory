geom_vline(xintercept = theta2, lwd = 1, colour = 'red', show.legend = TRUE) +
annotate("text", x=theta1 + .02, y=2, label="Theta 1", angle=90)
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
geom_vline(xintercept = theta1, lwd = 1, show.legend = TRUE) +
geom_vline(xintercept = theta2, lwd = 1, colour = 'red', show.legend = TRUE) +
annotate("text", x=theta1 + .02, y=2, label="Theta 1", angle=90) +
annotate("text", x=theta2 + .02, y=2, label="Theta 2", colour = 'red', angle=90)
postd1
postd2
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
geom_vline(xintercept = theta1, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = theta2, lwd = 1, colour = 'red', show.legend = TRUE) +
geom_vline(xintercept = 0.3491442, lwd = 1, lty = 2, show.legend = TRUE) +
geom_vline(xintercept = 0.9147666, lwd = 1, lty = 2, show.legend = TRUE) +
annotate("text", x=theta1 + .02, y=2, label="Theta 1", colour = 'blue', angle=90) +
annotate("text", x=theta2 + .02, y=2, label="Theta 2", colour = 'red', angle=90)
theta1 <- 0.92
theta2 <- 0.36
postd1 <- dbeta(theta1, shape1 = alpha.p, shape2 = beta.p)
postd1
postd2 <- dbeta(theta2, shape1 = alpha.p, shape2 = beta.p)
postd2
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
geom_vline(xintercept = theta1, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = theta2, lwd = 1, colour = 'red', show.legend = TRUE) +
geom_vline(xintercept = 0.3491442, lwd = 1, lty = 2, show.legend = TRUE) +
geom_vline(xintercept = 0.9147666, lwd = 1, lty = 2, show.legend = TRUE) +
annotate("text", x=theta1 + .02, y=2, label="Theta 1", colour = 'blue', angle=90) +
annotate("text", x=theta2 + .02, y=2, label="Theta 2", colour = 'red', angle=90)
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
geom_vline(xintercept = 0.3491442, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = 0.9147666, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = 0.3788, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = 0.9348, lwd = 1, colour = 'blue', show.legend = TRUE) +
scale_color_manual(name = "95% CI Type", values = c(equal-tailed = "blue", HPD = "red"))
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
geom_vline(xintercept = 0.3491442, lwd = 1, colour = 'blue', show_guide = TRUE) +
geom_vline(xintercept = 0.9147666, lwd = 1, colour = 'blue', show_guide = TRUE) +
geom_vline(xintercept = 0.3788, lwd = 1, colour = 'blue', show_guide = TRUE) +
geom_vline(xintercept = 0.9348, lwd = 1, colour = 'blue', show_guide = TRUE)
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
geom_vline(xintercept = 0.3491442, lwd = 1, colour = 'blue', show_guide = TRUE) +
geom_vline(xintercept = 0.9147666, lwd = 1, colour = 'blue', show_guide = TRUE) +
geom_vline(xintercept = 0.3788, lwd = 1, colour = 'red', show_guide = TRUE) +
geom_vline(xintercept = 0.9348, lwd = 1, colour = 'red', show_guide = TRUE)
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
geom_vline(xintercept = 0.3491442, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = 0.9147666, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = 0.3788, lwd = 1, colour = 'red', show.legend =  TRUE) +
geom_vline(xintercept = 0.9348, lwd = 1, colour = 'red', show.legend =  TRUE) +
annotate("text", x= 0.3491442 - .02, y=2, label="even-tailed", colour = 'blue', angle=90) +
annotate("text", x= 0.3788 + .02, y=2, label="HPD", colour = 'red', angle=90)
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
geom_vline(xintercept = 0.3491442, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = 0.9147666, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = 0.3788, lwd = 1, colour = 'red', show.legend =  TRUE) +
geom_vline(xintercept = 0.9348, lwd = 1, colour = 'red', show.legend =  TRUE) +
annotate("text", x= 0.3491442 - .02, y=2, label="even-tailed", colour = 'blue', angle=90) +
annotate("text", x= 0.3788 + .01, y=2, label="HPD", colour = 'red', angle=90)
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
geom_vline(xintercept = 0.3491442, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = 0.9147666, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = 0.3788, lwd = 1, colour = 'red', show.legend =  TRUE) +
geom_vline(xintercept = 0.9348, lwd = 1, colour = 'red', show.legend =  TRUE) +
annotate("text", x= 0.3491442 - .02, y=2, label="even-tailed", colour = 'blue', angle=90) +
annotate("text", x= 0.3788 + .01, y=2, label="HPD", colour = 'red', angle=90)
hpd_width <- 0.9348 - 0.3788
hpd_width
even_tail_width <- 0.9147666 - 0.3491442
even_tail_width
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
geom_vline(xintercept = 0.3491442, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = 0.9147666, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = 0.3788, lwd = 1, colour = 'red', show.legend =  TRUE) +
geom_vline(xintercept = 0.9348, lwd = 1, colour = 'red', show.legend =  TRUE) +
annotate("text", x= 0.3491442 - .02, y=2, label="even-tailed", colour = 'blue', angle=90) +
annotate("text", x= 0.3788 + .01, y=2, label="HPD", colour = 'red', angle=90)
### Part i ###
interval_density <- pbeta(0.9348, shape1 = alpha.p, shape2 = beta.p) - pbeta(0.3788, shape1 = alpha.p, shape2 = beta.p)
interval_density
### Part ii ###
hpd_width <- 0.9348 - 0.3788
hpd_width
even_tail_width <- 0.9147666 - 0.3491442
even_tail_width
alpha1 <- 1
beta1 <- 3
prob_part_a <- 1 - pbeta(0.2, shape1 = alpha1, shape2 = beta1)
prob_part_a
alpha1 <- 1
beta1 <- 3
prob_part_a <- 1 - pbeta(0.2, shape1 = alpha1, shape2 = beta1)
prob_part_a
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha1, shape2 = beta1)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3")
alpha1 <- 1
beta1 <- 3
prob_part_a <- 1 - pbeta(0.2, shape1 = alpha1, shape2 = beta1)
prob_part_a
# ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
#   stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha1, shape2 = beta1)) +
#   ylab(expression(pi(theta))) + xlab(expression(theta)) +
#   ggtitle("Posterior Distribution with Alpha = 6, Beta = 3")
alpha1 <- 1
beta1 <- 3
prob_part_a <- 1 - pbeta(0.2, shape1 = alpha1, shape2 = beta1)
prob_part_a
# ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
#   stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha1, shape2 = beta1)) +
#   ylab(expression(pi(theta))) + xlab(expression(theta)) +
#   ggtitle("Posterior Distribution with Alpha = 6, Beta = 3")
n1 <- 18
y1 <- 7
alpha.p <- y1 + alpha1
beta.p <- n1 - y1 + beta1
alpha.p
beta.p
n1 <- 18
x1 <- 7
alpha.p <- x1 + alpha1
beta.p <- n1 - x1 + beta1
alpha.p
beta.p
prob_part_d <- 1 - pbeta(0.2, shape1 = alpha.p, shape2 = beta.p)
prob_part_a
prob_part_d <- 1 - pbeta(0.2, shape1 = alpha.p, shape2 = beta.p)
prob_part_a
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3")
tinytex::reinstall_tinytex(repository = "illinois")
install.packages(MikTex)
knitr::opts_chunk$set(echo = TRUE)
#install.packages('tidyverse')
#install.packages('rlang')
#install.packages('moments')
# remove.packages(rlange)
library(MikTex)
knitr::opts_chunk$set(echo = TRUE)
#install.packages('tidyverse')
#install.packages('rlang')
#install.packages('moments')
# remove.packages(rlange)
library(tinytex)
library(tidyverse)
library(ggplot2)
library(moments)
library(ggplot2)
tinytex::install_tinytex()
knitr::opts_chunk$set(echo = TRUE)
#install.packages('tidyverse')
#install.packages('rlang')
#install.packages('moments')
# remove.packages(rlange)
library(tinytex)
library(tidyverse)
library(ggplot2)
library(moments)
library(ggplot2)
#######################################################
## Equal-tailed 95% credible interval for Beta(6, 3) ##
#######################################################
alpha.p <- 6
beta.p <- 3
qbeta(c(.025, .975), alpha.p, beta.p)
#######################################################
## Find theta1  ##
#######################################################
theta1 <- 0.92
theta2 <- 0.36
postd1 <- dbeta(theta1, shape1 = alpha.p, shape2 = beta.p)
postd1
postd2 <- dbeta(theta2, shape1 = alpha.p, shape2 = beta.p)
postd2
######################################################
## Find theta1 and theta2 according to requirements ##
######################################################
theta1 <- 0.92
theta2 <- 0.36
postd1 <- dbeta(theta1, shape1 = alpha.p, shape2 = beta.p)
postd1
postd2 <- dbeta(theta2, shape1 = alpha.p, shape2 = beta.p)
postd2
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
geom_vline(xintercept = theta1, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = theta2, lwd = 1, colour = 'red', show.legend = TRUE) +
geom_vline(xintercept = 0.3491442, lwd = 1, lty = 2, show.legend = TRUE) +
geom_vline(xintercept = 0.9147666, lwd = 1, lty = 2, show.legend = TRUE) +
annotate("text", x=theta1 + .02, y=2, label="Theta 1", colour = 'blue', angle=90) +
annotate("text", x=theta2 + .02, y=2, label="Theta 2", colour = 'red', angle=90) +
annotate("text", x=0.3491442 - .03, y=2, label="CI", colour = 'black', angle=90) +
annotate("text", x=0.9147666 - .03, y=2, label="CI", colour = 'black', angle=90)
#############
## 95% HPD ##
#############
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
geom_vline(xintercept = 0.3491442, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = 0.9147666, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = 0.3788, lwd = 1, colour = 'red', show.legend =  TRUE) +
geom_vline(xintercept = 0.9348, lwd = 1, colour = 'red', show.legend =  TRUE) +
annotate("text", x= 0.3491442 - .02, y=2, label="even-tailed", colour = 'blue', angle=90) +
annotate("text", x= 0.3788 + .02, y=2, label="HPD", colour = 'red', angle=90)
### Part i ###
interval_density <- pbeta(0.9348, shape1 = alpha.p, shape2 = beta.p) - pbeta(0.3788, shape1 = alpha.p, shape2 = beta.p)
interval_density
### Part ii ###
hpd_width <- 0.9348 - 0.3788
hpd_width
even_tail_width <- 0.9147666 - 0.3491442
even_tail_width
alpha1 <- 1
beta1 <- 3
prob_part_a <- 1 - pbeta(0.2, shape1 = alpha1, shape2 = beta1)
prob_part_a
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha1, shape2 = beta1)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
geom_vline(xintercept = .2, lwd = 1, colour = 'red', show.legend =  TRUE)
n1 <- 18
x1 <- 7
alpha.p <- x1 + alpha1
beta.p <- n1 - x1 + beta1
alpha.p
beta.p
prob_part_d <- 1 - pbeta(0.2, shape1 = alpha.p, shape2 = beta.p)
prob_part_a
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 8, Beta = 14")
prob_part_d <- 1 - pbeta(0.2, shape1 = alpha.p, shape2 = beta.p)
prob_part_d
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 8, Beta = 14")
alpha1 <- 1
beta1 <- 3
prob_part_a <- 1 - pbeta(0.2, shape1 = alpha1, shape2 = beta1)
prob_part_a
# ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
#   stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha1, shape2 = beta1)) +
#   ylab(expression(pi(theta))) + xlab(expression(theta)) +
#   ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
#   geom_segment(aes)
##########################################################
## 95% credible interval for the posterior distribution ##
##########################################################
qbeta(c(.025, .975), alpha.p, beta.p)
#####################################
## 95% credible interval for theta ##
#####################################
qbeta(c(.025, .975), alpha.p, beta.p)
############################
## Posterior Distribution ##
############################
n1 <- 18
x1 <- 7
alpha.p <- x1 + alpha1
beta.p <- n1 - x1 + beta1
alpha.p
beta.p
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 8, Beta = 14")
#################################
## Probability under posterior ##
#################################
prob_part_d <- 1 - pbeta(0.2, shape1 = alpha.p, shape2 = beta.p)
prob_part_d
n <- 300
x1 <- 75
alpha1 <- 3
beta1 <- 10
alpha.p <- x1 + alpha1
beta.p <- n - x1 + beta1
curve(dbeta(x, alpha.p, beta.p), n=1000, xlab=expression(theta), ylab="density",
main="Beta Prior vs Beta Posterior Distributions in Bayesian Analysis")
curve(dbeta(x, alpha1, beta1), add=T, lty=2)
legend("topright", legend=c("Posterior Alpha/Beta = 78/235", "Prior Alpha/Beta = 3/10"),
lty=c(1,2))
n <- 300 # sample size
x1 <- 75 # hypothetical number of successes
# Prior alpha and beta:
alpha1 <- 3
beta1 <- 10
# Posterior alpha and beta
alpha.p <- x1 + alpha1
beta.p <- n - x1 + beta1
curve(dbeta(x, alpha.p, beta.p), n=1000, xlab=expression(theta), ylab="density",
main="Beta Prior vs Beta Posterior Distributions in Bayesian Analysis")
curve(dbeta(x, alpha1, beta1), add=T, lty=2)
legend("topright", legend=c("Posterior Alpha/Beta = 78/235", "Prior Alpha/Beta = 3/10"),
lty=c(1,2))
#Part A
set.seed(35)
function_1 <- function(n) {
var_x <- c(-4, -3, -2, -1, 0, 1)
probx <- c(.04, .11, .25, .3, .18, .12)
d1 <- sample(x=var_x, size=n, replace = TRUE, prob = probx)
}
Simulation_1 <- function_1(500)
Simulation_1
var_xtable <- table(Simulation_1) |>prop.table() #this helps create a simple pdf table
barplot(var_xtable)
#Part B
sum(Simulation_1<0)/500
#Part C
mean(Simulation_1)
#Part D
Y <- 2*Simulation_1+1
table(Y)/500
#Part E
Y2 <- -2*Simulation_1+1
mean(Y2)
set.seed(1)
sim_X <- function(n) {
x <- -4:1
p <- c(0.04, 0.11, 0.25, 0.3, 0.18, 0.12)
sample(x, size = n, replace = TRUE, prob = p)
}
samples_x <- sim_X(10e3)
tab <- table(samples_x) |> prop.table()
tab
mean(samples_x < 0)
setwd("~/byu_fall_2023/Stat_348/STAT348/AmazonEmployeeAccess/data")
library(tidyverse)
#install.packages('tidymodels')
#install.packages('tidyverse')
library(tidymodels)
#install.packages('DataExplorer')
#install.packages("poissonreg")
library(poissonreg)
# install.packages("glmnet")
library(glmnet)
library(patchwork)
# install.packages("rpart")
# install.packages('ranger')
library(ranger)
#install.packages('stacks')
library(stacks)
library(vroom)
library(parsnip)
# install.packages('dbarts')
# library(dbarts)
install.packages('embed')
library(embed)
data_train <- vroom("train.csv") %>%
mutate(ACTION=factor(ACTION))# grab training data
data_train
rFormula <- ACTION ~ .
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .01) %>% # get hours
step_dummy(all_nominal_predictors()) # get dummy variables
prepped_recipe <- prep(my_recipe) # preprocessing new data
baked_data1 <- bake(prepped_recipe, new_data = data_train)
log_reg <- logistic_reg() %>% #Type of model
set_engine("glmnet")
data_train <- vroom("train.csv") %>%
mutate(ACTION=factor(ACTION))# grab training data
data_train
rFormula <- ACTION ~ .
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_lencode_mixed(all_numeric_predictors(), outcome = vars(ACTION)) %>%
step_other(all_nominal_predictors(), threshold = .001) # get hours
prepped_recipe <- prep(my_recipe) # preprocessing new data
baked_data1 <- bake(prepped_recipe, new_data = data_train)
log_reg <- logistic_reg(mixture = tune(), penalty = tune()) %>% #Type of model
set_engine("glmnet")
pretune_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(log_reg)
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 tuning possibilities
# Split data for CV
folds <- vfold_cv(data_train, v = 10, repeats = 1)
# Run CV
CV_results <- pretune_workflow %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc, f_meas))
# Run CV
CV_results <- pretune_workflow %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc))
install.packages('lme4')
library(lme4)
# Run CV
CV_results <- pretune_workflow %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc))
data_train <- vroom("train.csv") %>%
mutate(ACTION=factor(ACTION))# grab training data
rFormula <- ACTION ~ .
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_lencode_mixed(all_numeric_predictors(), outcome = vars(ACTION)) %>%
step_other(all_nominal_predictors(), threshold = .001) # get hours
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .001) %>%
step_lencode_mixed(all_numeric_predictors(), outcome = vars(ACTION))# get hours
prepped_recipe <- prep(my_recipe) # preprocessing new data
baked_data1 <- bake(prepped_recipe, new_data = data_train)
log_reg <- logistic_reg(mixture = tune(), penalty = tune()) %>% #Type of model
set_engine("glmnet")
pretune_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(log_reg)
# Grid for CV
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 tuning possibilities
# Split data for CV
folds <- vfold_cv(data_train, v = 10, repeats = 1)
# Run CV
CV_results <- pretune_workflow %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc))
.Last.tune.result
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .001) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))# get hours
log_reg <- logistic_reg(mixture = tune(), penalty = tune()) %>% #Type of model
set_engine("glmnet")
pretune_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(log_reg)
# Grid for CV
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 tuning possibilities
# Split data for CV
folds <- vfold_cv(data_train, v = 10, repeats = 1)
# Run CV
CV_results <- pretune_workflow %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc))
bestTune <- CV_results %>%
select_best('roc_auc')
final_wf <- pretune_workflow %>%
finalize_workflow(bestTune) %>%
fit(data = data_train)
final_wf
data_test <- vroom("test.csv") # grab testing data
amazon_predictions <- predict(final_wf,
new_data=data_test,
type="prob") %>% # "class" or "prob"
mutate(Id = data_test$id) %>%
mutate(ACTION = ifelse(.pred_1 > .95, 1, 0)) %>%
select(-.pred_0, -.pred_1)
amazon_predictions
vroom_write(amazon_predictions, "amazon_logreg_target.csv", delim = ",")
rFormula
my_recipe
baked_data1
log_reg
pretune_workflow
tuning_grid
CV_results
bestTune
final_wf
bestTune
