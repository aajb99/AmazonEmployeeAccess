## 95% HPD ##
#############
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
geom_vline(xintercept = 0.3491442, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = 0.9147666, lwd = 1, colour = 'blue', show.legend = TRUE) +
geom_vline(xintercept = 0.3788, lwd = 1, colour = 'red', show.legend =  TRUE) +
geom_vline(xintercept = 0.9348, lwd = 1, colour = 'red', show.legend =  TRUE) +
annotate("text", x= 0.3491442 - .02, y=2, label="even-tailed", colour = 'blue', angle=90) +
annotate("text", x= 0.3788 + .02, y=2, label="HPD", colour = 'red', angle=90)
### Part i ###
interval_density <- pbeta(0.9348, shape1 = alpha.p, shape2 = beta.p) - pbeta(0.3788, shape1 = alpha.p, shape2 = beta.p)
interval_density
### Part ii ###
hpd_width <- 0.9348 - 0.3788
hpd_width
even_tail_width <- 0.9147666 - 0.3491442
even_tail_width
alpha1 <- 1
beta1 <- 3
prob_part_a <- 1 - pbeta(0.2, shape1 = alpha1, shape2 = beta1)
prob_part_a
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha1, shape2 = beta1)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
geom_vline(xintercept = .2, lwd = 1, colour = 'red', show.legend =  TRUE)
n1 <- 18
x1 <- 7
alpha.p <- x1 + alpha1
beta.p <- n1 - x1 + beta1
alpha.p
beta.p
prob_part_d <- 1 - pbeta(0.2, shape1 = alpha.p, shape2 = beta.p)
prob_part_a
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 8, Beta = 14")
prob_part_d <- 1 - pbeta(0.2, shape1 = alpha.p, shape2 = beta.p)
prob_part_d
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 8, Beta = 14")
alpha1 <- 1
beta1 <- 3
prob_part_a <- 1 - pbeta(0.2, shape1 = alpha1, shape2 = beta1)
prob_part_a
# ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
#   stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha1, shape2 = beta1)) +
#   ylab(expression(pi(theta))) + xlab(expression(theta)) +
#   ggtitle("Posterior Distribution with Alpha = 6, Beta = 3") +
#   geom_segment(aes)
##########################################################
## 95% credible interval for the posterior distribution ##
##########################################################
qbeta(c(.025, .975), alpha.p, beta.p)
#####################################
## 95% credible interval for theta ##
#####################################
qbeta(c(.025, .975), alpha.p, beta.p)
############################
## Posterior Distribution ##
############################
n1 <- 18
x1 <- 7
alpha.p <- x1 + alpha1
beta.p <- n1 - x1 + beta1
alpha.p
beta.p
ggplot(data = data.frame(x = c(0, 1)), aes(x)) +
stat_function(fun = dbeta, n = 500, args = list(shape1 = alpha.p, shape2 = beta.p)) +
ylab(expression(pi(theta))) + xlab(expression(theta)) +
ggtitle("Posterior Distribution with Alpha = 8, Beta = 14")
#################################
## Probability under posterior ##
#################################
prob_part_d <- 1 - pbeta(0.2, shape1 = alpha.p, shape2 = beta.p)
prob_part_d
n <- 300
x1 <- 75
alpha1 <- 3
beta1 <- 10
alpha.p <- x1 + alpha1
beta.p <- n - x1 + beta1
curve(dbeta(x, alpha.p, beta.p), n=1000, xlab=expression(theta), ylab="density",
main="Beta Prior vs Beta Posterior Distributions in Bayesian Analysis")
curve(dbeta(x, alpha1, beta1), add=T, lty=2)
legend("topright", legend=c("Posterior Alpha/Beta = 78/235", "Prior Alpha/Beta = 3/10"),
lty=c(1,2))
n <- 300 # sample size
x1 <- 75 # hypothetical number of successes
# Prior alpha and beta:
alpha1 <- 3
beta1 <- 10
# Posterior alpha and beta
alpha.p <- x1 + alpha1
beta.p <- n - x1 + beta1
curve(dbeta(x, alpha.p, beta.p), n=1000, xlab=expression(theta), ylab="density",
main="Beta Prior vs Beta Posterior Distributions in Bayesian Analysis")
curve(dbeta(x, alpha1, beta1), add=T, lty=2)
legend("topright", legend=c("Posterior Alpha/Beta = 78/235", "Prior Alpha/Beta = 3/10"),
lty=c(1,2))
#Part A
set.seed(35)
function_1 <- function(n) {
var_x <- c(-4, -3, -2, -1, 0, 1)
probx <- c(.04, .11, .25, .3, .18, .12)
d1 <- sample(x=var_x, size=n, replace = TRUE, prob = probx)
}
Simulation_1 <- function_1(500)
Simulation_1
var_xtable <- table(Simulation_1) |>prop.table() #this helps create a simple pdf table
barplot(var_xtable)
#Part B
sum(Simulation_1<0)/500
#Part C
mean(Simulation_1)
#Part D
Y <- 2*Simulation_1+1
table(Y)/500
#Part E
Y2 <- -2*Simulation_1+1
mean(Y2)
set.seed(1)
sim_X <- function(n) {
x <- -4:1
p <- c(0.04, 0.11, 0.25, 0.3, 0.18, 0.12)
sample(x, size = n, replace = TRUE, prob = p)
}
samples_x <- sim_X(10e3)
tab <- table(samples_x) |> prop.table()
tab
mean(samples_x < 0)
knitr::opts_chunk$set(echo = TRUE)
#uncomment any of these that you will want to use (and add any others)
#install.packages('tidyverse')
#install.packages('rlang')
#install.packages('moments')
# remove.packages(rlange)
library(tinytex)
library(tidyverse)
library(ggplot2)
library(moments)
alpha <- 0.5
beta <- 3
curve(dbeta(x, alpha, beta), n=1000, xlab=expression(theta), ylab="density", main="Prior Distribution (Both Genders)")
alpha <- 0.5
beta <- 3
curve(dbeta(x, alpha, beta), n=1000, xlab=expression(theta), ylab="density", main="Prior Distribution (Both Genders)")
prob1 <- pbeta(0.1, shape1 = alpha, shape2 = beta)
prob1
knitr::opts_chunk$set(echo = TRUE)
#uncomment any of these that you will want to use (and add any others)
#install.packages('tidyverse')
#install.packages('rlang')
#install.packages('moments')
# remove.packages(rlange)
library(tinytex)
library(tidyverse)
library(ggplot2)
library(moments)
alpha <- 0.5
beta <- 3
curve(dbeta(x, alpha, beta), n=1000, xlab=expression(theta), ylab="density", main="Prior Distribution (Both Genders)")
prob1 <- pbeta(0.1, shape1 = alpha, shape2 = beta)
prob1
# Data collected
n_1 <- 1260
x_1 <- 67
n_2 <- 1700
x_2 <- 173
# Posterior parameters
alpha_p_1 <- alpha + x_1
beta_p_1 <- beta + n_1 - x_1
alpha_p_2 <- alpha + x_2
beta_p_2 <- beta + n_2 - x_2
# Posterior distributions
curve(dbeta(x, alpha_p_1, beta_p_1), ylim=c(0, 30), xlab=expression(theta), ylab="posterior density", main="Posterior Prob. Dist. of Proportion of Skipped Questions", lwd=2)
curve(dbeta(x, alpha_p_2, beta_p_2), add=T, col="blue", lwd=2, lty=2)
legend("topright", legend=c("Men", "Women"), col=c("black", "blue"), lwd=2, lty=c(1,2))
# Data collected
n_1 <- 1260
x_1 <- 67
n_2 <- 1700
x_2 <- 173
# Posterior parameters
alpha_p_1 <- alpha + x_1
beta_p_1 <- beta + n_1 - x_1
alpha_p_2 <- alpha + x_2
beta_p_2 <- beta + n_2 - x_2
# Posterior distributions
curve(dbeta(x, alpha_p_1, beta_p_1), xlim = c(0, 0.2), ylim=c(0, 50), xlab=expression(theta), ylab="posterior density", main="Posterior Prob. Dist. of Proportion of Skipped Questions", lwd=2)
curve(dbeta(x, alpha_p_2, beta_p_2), add=T, col="blue", lwd=2)
legend("topright", legend=c("Men", "Women"), col=c("black", "blue"), lwd=2, lty=c(1,2))
# Data collected
n_1 <- 1260
x_1 <- 67
n_2 <- 1700
x_2 <- 173
# Posterior parameters
alpha_p_1 <- alpha + x_1
beta_p_1 <- beta + n_1 - x_1
alpha_p_2 <- alpha + x_2
beta_p_2 <- beta + n_2 - x_2
# Posterior distributions
curve(dbeta(x, alpha_p_1, beta_p_1), xlim = c(0, 0.2), ylim=c(0, 65), xlab=expression(theta), ylab="posterior density", main="Posterior Prob. Dist. of Proportion of Skipped Questions", lwd=2)
curve(dbeta(x, alpha_p_2, beta_p_2), add=T, col="blue", lwd=2)
legend("topright", legend=c("Men", "Women"), col=c("black", "blue"), lwd=2, lty=c(1,2))
alpha_p_1
beta_p_1
alpha_p_2
beta_p_2
prob_m <- pbeta(0.1, shape1 = alpha_p_1, shape2 = beta_p_1)
prob_m
prob_w <- pbeta(0.1, shape1 = alpha_p_2, shape2 = beta_p_2)
prob_w
# Data collected
n_1 <- 1260
x_1 <- 67
n_2 <- 1700
x_2 <- 173
# Posterior parameters
alpha_p_1 <- alpha + x_1
beta_p_1 <- beta + n_1 - x_1
alpha_p_2 <- alpha + x_2
beta_p_2 <- beta + n_2 - x_2
# Posterior distributions
curve(dbeta(x, alpha_p_1, beta_p_1), xlim = c(0, 0.2), ylim=c(0, 65), xlab=expression(theta), ylab="posterior density", main="Posterior Prob. Dist. of Proportion of Skipped Questions", lwd=2)
curve(dbeta(x, alpha_p_2, beta_p_2), add=T, col="blue", lwd=2)
legend("topright", legend=c("Men", "Women"), col=c("black", "blue"), lwd=2, lty=c(1,1))
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta.m.dot - theta.w.dot
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_m_dot - theta_w_dot
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_m_dot - theta_w_dot
theta_m_dot
theta_w_dot
d.dot
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_m_dot - theta_w_dot
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_w_dot - theta_m_dot
plot(density(d.dot), main=expression(paste("Posterior on the difference between proportion of skipped questions by women and men", theta[1]-theta[2])), xlab=expression(d==theta[1]-theta[2]), lwd=3)
abline(v=0, lty=2)
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_w_dot - theta_m_dot
plot(density(d.dot), main=expression(paste("Posterior on the difference", theta[1]-theta[2])), xlab=expression(d==theta[1]-theta[2]), lwd=3)
abline(v=0, lty=2)
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_w_dot - theta_m_dot
plot(density(d.dot), main=expression(paste("Posterior on the difference", theta[1]-theta[2])), xlab=expression(d==theta[1]-theta[2]), lwd=3)
abline(v=0, lty=2)
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_w_dot - theta_m_dot
plot(density(d.dot), main=expression(paste("Posterior on the difference", theta[1]-theta[2])), xlab=expression(d==theta[W]-theta[M]), lwd=3)
abline(v=0, lty=2)
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_w_dot - theta_m_dot
plot(density(d.dot), main=expression(paste("Posterior on the difference", theta[1]-theta[2])), xlab=expression(d==theta[W]-theta[M]), lwd=3)
abline(v=0, lty=2)
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_w_dot - theta_m_dot
plot(density(d.dot), main=expression(paste("Posterior on the difference", theta[1]-theta[2])), xlab=expression(d==theta[W]-theta[M]), lwd=3)
abline(v=0, lty=2)
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_w_dot - theta_m_dot
plot(density(d.dot), main=expression(paste("Posterior on the difference", theta[1]-theta[2])), xlab=expression(d==theta[W]-theta[M]), lwd=3)
abline(v=0, lty=2)
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_w_dot - theta_m_dot
plot(density(d.dot), main=expression(paste("Posterior on the difference", theta[1]-theta[2])), xlab=expression(d==theta[W]-theta[M]), lwd=3)
abline(v=0, lty=2)
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_w_dot - theta_m_dot
plot(density(d.dot), main=expression(paste("Posterior on the difference", theta[1]-theta[2])), xlab=expression(d==theta[W]-theta[M]), lwd=3)
abline(v=0, lty=2)
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_w_dot - theta_m_dot
plot(density(d.dot), main=expression(paste("Posterior on the difference", theta[1]-theta[2])), xlab=expression(d==theta[W]-theta[M]), lwd=3)
abline(v=0, lty=2)
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_w_dot - theta_m_dot
plot(density(d.dot), main=expression(paste("Posterior on the difference", theta[1]-theta[2])), xlab=expression(d==theta[W]-theta[M]), lwd=3)
abline(v=0, lty=2)
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_w_dot - theta_m_dot
plot(density(d.dot), main=expression(paste("Posterior on the difference", theta[1]-theta[2])), xlab=expression(d==theta[W]-theta[M]), lwd=3)
abline(v=0, lty=2)
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_w_dot - theta_m_dot
plot(density(d.dot), main=expression(paste("Posterior on the difference", theta[1]-theta[2])), xlab=expression(d==theta[W]-theta[M]), lwd=3)
abline(v=0, lty=2)
mean(theta_w_dot > theta_m_dot)
# Posterior on the difference
theta_m_dot <- rbeta(10000, alpha_p_1, beta_p_1)
theta_w_dot <- rbeta(10000, alpha_p_2, beta_p_2)
d.dot <- theta_w_dot - theta_m_dot
plot(density(d.dot), main=expression(paste("Posterior on the difference", theta[1]-theta[2])), xlab=expression(d==theta[W]-theta[M]), lwd=3)
abline(v=0, lty=2)
mean(theta_w_dot > theta_m_dot)
quantile(d.dot, c(.025, .975))
# different gamma distributions
curve(dgamma(x, shape = 2, rate = 3), xlim = c(0, 15), ylim=c(0, 65), xlab='X', ylab="Density", main="Gamma Distributions", lwd=2)
curve(dgamma(x, shape = 7, rate = 3), add=T, col="blue", lwd=2)
legend("topright", legend=c("Shape = 2", "Shape = 7"), col=c("black", "blue"), lwd=2, lty=c(1,1))
# different gamma distributions
curve(dgamma(x, shape = 2, rate = 3), xlim = c(0, 15), ylim=c(0, 8), xlab='X', ylab="Density", main="Gamma Distributions", lwd=2)
curve(dgamma(x, shape = 7, rate = 3), add=T, col="blue", lwd=2)
legend("topright", legend=c("Shape = 2", "Shape = 7"), col=c("black", "blue"), lwd=2, lty=c(1,1))
# different gamma distributions
curve(dgamma(x, shape = 2, rate = 3), xlim = c(0, 15), ylim=c(0, 1), xlab='X', ylab="Density", main="Gamma Distributions", lwd=2)
curve(dgamma(x, shape = 7, rate = 3), add=T, col="blue", lwd=2)
legend("topright", legend=c("Shape = 2", "Shape = 7"), col=c("black", "blue"), lwd=2, lty=c(1,1))
# different gamma distributions
curve(dgamma(x, shape = 2, rate = 3), xlim = c(0, 8), ylim=c(0, 1.5), xlab='X', ylab="Density", main="Gamma Distributions", lwd=2)
curve(dgamma(x, shape = 7, rate = 3), add=T, col="blue", lwd=2)
legend("topright", legend=c("Shape = 2", "Shape = 7"), col=c("black", "blue"), lwd=2, lty=c(1,1))
# different gamma distributions
curve(dgamma(x, shape = 2, rate = 3), xlim = c(0, 8), ylim=c(0, 1.25), xlab='X', ylab="Density", main="Gamma Distributions", lwd=2)
curve(dgamma(x, shape = 7, rate = 3), add=T, col="blue", lwd=2)
legend("topright", legend=c("Shape = 2", "Shape = 7"), col=c("black", "blue"), lwd=2, lty=c(1,1))
# different gamma distributions
curve(dgamma(x, shape = 2, rate = 3), xlim = c(0, 8), ylim=c(0, 1.25), xlab='X', ylab="Density", main="Gamma Distributions (Rate = 3)", lwd=2)
curve(dgamma(x, shape = 7, rate = 3), add=T, col="blue", lwd=2)
legend("topright", legend=c("Shape = 2", "Shape = 7"), col=c("black", "blue"), lwd=2, lty=c(1,1))
# gamma distributions by differing rate
curve(dgamma(x, shape = 5, rate = 3), xlim = c(0, 8), ylim=c(0, 1.25), xlab='X', ylab="Density", main="Gamma Distributions (Shape = 5)", lwd=2)
curve(dgamma(x, shape = 5, rate = 10), add=T, col="blue", lwd=2)
legend("topright", legend=c("Rate = 3", "Rate = 10"), col=c("black", "blue"), lwd=2, lty=c(1,1))
# gamma distributions by differing rate
curve(dgamma(x, shape = 5, rate = 3), xlim = c(0, 6), ylim=c(0, 3), xlab='X', ylab="Density", main="Gamma Distributions (Shape = 5)", lwd=2)
curve(dgamma(x, shape = 5, rate = 10), add=T, col="blue", lwd=2)
legend("topright", legend=c("Rate = 3", "Rate = 10"), col=c("black", "blue"), lwd=2, lty=c(1,1))
# gamma distributions by differing rate
curve(dgamma(x, shape = 5, rate = 3), xlim = c(0, 6), ylim=c(0, 2.1), xlab='X', ylab="Density", main="Gamma Distributions (Shape = 5)", lwd=2)
curve(dgamma(x, shape = 5, rate = 10), add=T, col="blue", lwd=2)
legend("topright", legend=c("Rate = 3", "Rate = 10"), col=c("black", "blue"), lwd=2, lty=c(1,1))
dpois(2, lambda = 14, log = False)
dpois(2, lambda = 14, log = FALSE)
knitr::opts_chunk$set(echo = TRUE)
#uncomment any of these that you will want to use (and add any others)
#install.packages('tidyverse')
#install.packages('rlang')
#install.packages('moments')
# remove.packages(rlange)
library(tinytex)
library(tidyverse)
library(ggplot2)
library(moments)
shape <- 2
rate <- 1.5
curve(dgamma(x, shape, rate), n=1000, xlab=expression(lambda), ylab="density", main="Gamma Dist Shape = 2, Rate = 1.5")
# prob1 <- pbeta(0.1, shape1 = alpha, shape2 = beta)
# prob1
shape <- 2
rate <- 1.5
curve(dgamma(x, shape, rate), n=1000, xlab=expression(lambda), ylab="density", main="Gamma Dist Shape = 2, Rate = 1.5", xlim = c(0, 5))
# prob1 <- pbeta(0.1, shape1 = alpha, shape2 = beta)
# prob1
shape <- 2
rate <- 1.5
curve(dgamma(x, shape, rate), n=1000, xlab=expression(lambda), ylab="density", main="Gamma Dist Shape = 2, Rate = 1.5", xlim = c(0, 6))
# prob1 <- pbeta(0.1, shape1 = alpha, shape2 = beta)
# prob1
shape <- 2
rate <- 1.5
curve(dgamma(x, shape, rate), n=1000, xlab=expression(lambda), ylab="density", main="Gamma Dist Shape = 2, Rate = 1.5", xlim = c(0, 7))
# prob1 <- pbeta(0.1, shape1 = alpha, shape2 = beta)
# prob1
shape <- 2
rate <- 1.5
curve(dgamma(x, shape, rate), n=1000, xlab=expression(lambda), ylab="density", main="Gamma Dist Shape = 2, Rate = 1.5", xlim = c(0, 7))
prob2 <- pgamma(5, shape = shape, rate = rate) - pgamma(2, shape = shape, rate = rate)
prob2
qgamma(c(.025, .975), shape, rate)
#install.packages('tidyverse')
library(tidyverse)
#install.packages('tidymodels')
library(tidymodels)
#install.packages('DataExplorer')
#install.packages("poissonreg")
# library(poissonreg)
#install.packages("glmnet")
library(glmnet)
#library(patchwork)
# install.packages("rpart")
#install.packages('ranger')
library(ranger)
#install.packages('stacks')
library(stacks)
#install.packages('vroom')
library(vroom)
#install.packages('parsnip')
library(parsnip)
# install.packages('dbarts')
# library(dbarts)
#install.packages('embed')
library(embed)
setwd("~/byu_fall_2023/Stat_348/STAT348/AmazonEmployeeAccess")
rFormula <- ACTION ~ .
data_train <- vroom("./data/train.csv") %>%
mutate(ACTION=factor(ACTION))# grab training data
data_train
rFormula <- ACTION ~ .
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .001) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) %>% # get hours
step_normalize()
prepped_recipe <- prep(my_recipe) # preprocessing new data
baked_data1 <- bake(prepped_recipe, new_data = data_train)
## knn model
knn_model <- nearest_neighbor(neighbors=tune()) %>% # set or tune
set_mode("classification") %>%
set_engine("kknn")
knn_wf <- workflow() %>%
add_recipe(myRecipe) %>%
add_model(knn_model)
knn_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(knn_model)
## Fit or Tune MOdel
tuning_grid <- grid_regular(neighbors(),
levels = 5) ## L^2 total tuning possibilities
# Split data for CV
folds <- vfold_cv(data_train, v = 10, repeats = 1)
# Run CV
CV_results <- knn_wf %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc))
install.packages('kknn')
library(kknn)
my_recipe <- recipe(rFormula, data = data_train) %>% # set model formula and dataset
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .001) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) %>% # get hours
step_normalize()
prepped_recipe <- prep(my_recipe) # preprocessing new data
baked_data1 <- bake(prepped_recipe, new_data = data_train)
## knn model
knn_model <- nearest_neighbor(neighbors=tune()) %>% # set or tune
set_mode("classification") %>%
set_engine("kknn")
knn_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(knn_model)
## Fit or Tune MOdel
tuning_grid <- grid_regular(neighbors(),
levels = 5) ## L^2 total tuning possibilities
# Split data for CV
folds <- vfold_cv(data_train, v = 10, repeats = 1)
# Run CV
CV_results <- knn_wf %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc))
bestTune <- CV_results %>%
select_best('roc_auc')
bestTune
final_wf <- knn_wf %>%
finalize_workflow(bestTune) %>%
fit(data = data_train)
data_test <- vroom("./data/test.csv") # grab testing data
amazon_predictions <- predict(final_wf,
new_data=data_test,
type="prob") %>% # "class" or "prob"
mutate(Id = data_test$id) %>%
#mutate(ACTION = ifelse(.pred_1 > .95, 1, 0)) %>%
mutate(ACTION = .pred_1) %>%
select(-.pred_0, -.pred_1)
amazon_predictions
vroom_write(amazon_predictions, "amazon_pred_knn.csv", delim = ",")
